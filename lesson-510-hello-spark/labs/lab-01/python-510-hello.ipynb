{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hello from a Python Notebook\n",
    "\n",
    "## Introduction\n",
    "\n",
    "In this exercise we'll follow up on the hello-world exercise that we did in the Spark Shell by parsing and executing code inside a Python enabled Notebook.\n",
    "\n",
    "We've put the lyrics of the song into a text file for you.  It's called `hello-adele.txt` and is placed in a mapped folder for the Notebooks (called `Resources`)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Running some code\n",
    "\n",
    "The code can be written in fragments. We'll start by creating a `SparkSession`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "\n",
    "spark = SparkSession.builder.appName(\"Python Spark SQL\").getOrCreate()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll use the naming convension of calling that session `spark` for our Python programmers. This is a little bit different from the Shell where we had an implicit sc object. We generally don't want to use the SparkContext as it can only be instantiated once per notebook. If someone runs the cell creating the context several times, they would experience an exception. The cell above can be executed multipe times."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we can create a relationship to the lines in the text file:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lines = spark.sparkContext.textFile(\"../Resources/hello-adele.txt\") # Assumes you are one in the work directory"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`lines` is now a relationship to an RDD. \n",
    "\n",
    "In Python, the way to access the first line is a bit different:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lines.first()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And the second line can be collected as:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lines.collect()[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the exercise, we also counted the lines. This can be done as follows in Python and Spark:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lines.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And of course we can get to all the words and read the first 5 perhaps?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lines.flatMap(lambda line: line.split(\" \")).take(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The syntax for lambda functions is quite different, but other than that, it is almost identical to what you would have to do in Scala."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That's probably enough... At think at this point we can jump to the final solution:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lines\\\n",
    ".flatMap(lambda line: line.split())\\\n",
    ".filter(lambda word: word != \"\")\\\n",
    ".map(lambda word: (word.lower(), 1))\\\n",
    ".reduceByKey(lambda lv,rv: lv + rv)\\\n",
    ".sortBy(lambda a : a[1], False)\\\n",
    ".take(5)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Congratulations!\n",
    "\n",
    "You just ran Spark inside a Notebook!\n",
    "\n",
    "Feel free to play around yourself in the cell below. Or you can make your own notes in the notebook. If you want to save some of the changes, make sure to export the notebook by selecting `File` -> `Download As` -> `Notebook`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
