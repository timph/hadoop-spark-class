{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Developing Spark Applications: PairRDDFunctions\n",
    "\n",
    "In this lab, you will take your first steps using PairRDDFunctions using Jupyter Notebook.\n",
    "\n",
    "### Objectives\n",
    "\n",
    "Use the SparkContext to bootstrap RDDs of Tuples in order to use PairRDDFunctions. Use the PairRDDFunctions to more easily calculate values in the RDD.\n",
    "\n",
    "### Consider Tuples\n",
    "\n",
    "Scala's support for arbitrary pairs (and triplets, quadruplets, and so on) of data is reflected in Spark. If an RDD's element is of a Tuple type, then, through Spark implicits, that RDD gets enriched with PairRDDFunctions, which provide convenient means of performing calculations on the Tuples.\n",
    "\n",
    "### Read external file into RDD\n",
    "\n",
    "You'll be using a file sherlock-holmes.txt. You need to retrieve it from the container folder (/home/jovyan/Resources) mounted to host machine directory - see instructions about setting up the Docker container to run Jupyter Notebook.\n",
    "\n",
    "Read text into RDD. \n",
    "\n",
    "Make sure that the file was read correctly by printing the RDD element count (here the number of lines in the file)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val file = \"/home/jovyan/Resources/sherlock-holmes.txt\"\n",
    "val lines = sc.textFile(file)\n",
    "\n",
    "print(lines.count)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get an RDD of Words\n",
    "\n",
    "Our goal is to count how many ifs, ands & buts there are in the file, so if we could somehow get a Map of word counts keyed on the word, we'd be golden.\n",
    "\n",
    "The first thing we need to do is to create an RDD that contains the words in the file. We already have the file loaded into an RDD called `lines` where each element is a line of text. Your next step is to split each line with the provided delimiters so that you end up with a flat collection of words in the file. Whenever we want to flatten a collection of collections, we can use flatMap to do so.\n",
    "\n",
    "We also want to remove all empty words by using the `filter` function, which accepts only the words, whose length is greater than zero. Note, that the RDD transforming functions could be strung together as you can see below.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val delimiters = Array(' ',',','.',':',';','?','!','-','@','#','(',')','*','_','/','\"','\"')\n",
    "\n",
    "val words = lines.flatMap(_.split(delimiters)).filter(_.length > 0)\n",
    "\n",
    "words.take(10).foreach(println)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### We'll consider two equivalent ways to accomplish our goal\n",
    "\n",
    "They will be using PairRDDFunctions, which operate on data organized as key-value pairs. The functions typically agregate values for the keys."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font color=blue>Use reduceByKey</font>\n",
    "\n",
    "One of the most useful PairRDDFunctions is `reduceByKey`, which transforms a pair RDD anto another pair RDD, where the values for each key are aggregated using the supplied reduce function.\n",
    "\n",
    "In our case, the pair's key is the word, and the value is the count. The initial value for each word is 1. \n",
    "\n",
    "The reduce function is a simple addition as we'll be adding the counts of the same words. The values will be aggregated, finally resulting in the total count for each distinct word.\n",
    "\n",
    "Let's transform our `words` RDD into initial `pairs` RDD and while we're at it convert words into lower case for better accuracy of the counts.\n",
    "\n",
    "Next we'll be applying `reduceByKey` function yielding the total word counts.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "val pairs = words.map(word => (word.toLowerCase, 1))\n",
    "\n",
    "val counts = pairs.reduceByKey(_ + _)\n",
    "\n",
    "counts.take(10).foreach(println)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Convert RDD into Map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val map = counts.collectAsMap\n",
    "\n",
    "val ifs  = map(\"if\")\n",
    "val ands = map(\"and\")\n",
    "val buts = map(\"but\")\n",
    "\n",
    "println(ifs)\n",
    "println(ands)\n",
    "println(buts)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font color=blue>Use countByKey</font>\n",
    "\n",
    "It just so happens that PairRDDFunctions has a method called `countByKey`, which returns a Map of counts of the occurrence of each key among the pairs. \n",
    "\n",
    "This function also requires a pair RDD. However, since it counts the occurrences of the keys it doesn't really matter what the values are (even the value type is irrelevant). Therefore we'll be using None as opposed to 1 as the initial value of the pairs.\n",
    "\n",
    "Note that unlike `reduceByKey` there is no need to collect RDD values into a Map as `countByKey` does it automatically."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val pairs = words.map(word => (word.toLowerCase, None))\n",
    "\n",
    "val counts = pairs.countByKey()\n",
    "\n",
    "val ifs  = counts(\"if\")\n",
    "val ands = counts(\"and\")\n",
    "val buts = counts(\"but\")\n",
    "\n",
    "println(ifs)\n",
    "println(ands)\n",
    "println(buts)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Other interesting things about Sherlock Holmes\n",
    "\n",
    "#### Find the word with the highest count\n",
    "\n",
    "We'll use `reduce` function, which out of two pair elements returns the one with the higher count (note the way we access the individual elements of pairs).\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "val maxCount = counts.reduce((r, c) => (if (r._2 > c._2) r else c))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Find the longest word\n",
    "\n",
    "We'll use `reduce` function, which out of two pair elements returns the one with the longer key.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "val maxWord = counts.reduce((r, c) => (if (r._1.length > c._1.length) r else c))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bonus Assignment\n",
    "\n",
    "#### Find all anagrams among words\n",
    "\n",
    "Can you write an algorithm that finds all the anograms (a word, phrase, or name formed by rearranging the letters of another, such as `cinema`, formed from `iceman`) in the text?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Your Solution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conclusion\n",
    "\n",
    "In this lab, we saw how an RDD of Tuple types receives via an implicit additional methods from PairRDDFunctions to make calculating certain values easier."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Suggested Solution\n",
    "\n",
    "This discussion written as one continuous set of code (without all the discussion)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val file = \"/home/jovyan/Resources/sherlock-holmes.txt\"\n",
    "val lines = sc.textFile(file)\n",
    "\n",
    "val delimiters = Array(' ',',','.',':',';','?','!','-','@','#','(',')','*','_','/','\"','\"')\n",
    "val words = lines.flatMap(_.split(delimiters)).filter(_.length > 0)\n",
    "\n",
    "val pairs = words.map(word => (word.toLowerCase, 1))\n",
    "val counts = pairs.reduceByKey(_ + _)\n",
    "val map = counts.collectAsMap\n",
    "\n",
    "val ifs  = map(\"if\")\n",
    "val ands = map(\"and\")\n",
    "val buts = map(\"but\")\n",
    "\n",
    "println(ifs)\n",
    "println(ands)\n",
    "println(buts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Solution for Bonus Assignment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val file = \"/home/jovyan/Resources/sherlock-holmes.txt\"\n",
    "val lines = sc.textFile(file)\n",
    "\n",
    "val delimiters = Array(' ',',','.',':',';','?','!','-','@','#','(',')','*','_','/',''','\"','\"')\n",
    "\n",
    "// We're interested in anagrams longer than 6 letters\n",
    "\n",
    "val words = lines.flatMap(_.split(delimiters)).filter(_.length > 6).map(word => word.toLowerCase).distinct\n",
    "\n",
    "// we're creating a pair RDD where the key is the original word sorted by letters \n",
    "// and the initial value is a singleton list with the word as an element\n",
    "// any two words sharing the same sorted forms are anagrams\n",
    "\n",
    "val pairs = words.map(word => (word.toList.sorted.mkString, List(word)))\n",
    "\n",
    "// the reduce function is concatenating lists of words (::: - operator to concatenate lists) \n",
    "// map is dropping the keys as they're no loner needed\n",
    "// filter is returning only those lists, which are longer than 1 (true anagrams)\n",
    "\n",
    "val angrs = pairs.reduceByKey(_ ::: _).map(_._2).filter(_.size > 1)\n",
    "\n",
    "angrs.collect.foreach(println(_))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Apache Toree - Scala",
   "language": "scala",
   "name": "apache_toree_scala"
  },
  "language_info": {
   "codemirror_mode": "text/x-scala",
   "file_extension": ".scala",
   "mimetype": "text/x-scala",
   "name": "scala",
   "pygments_lexer": "scala",
   "version": "2.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
