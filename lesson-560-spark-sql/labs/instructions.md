# Spark SQL

## Instructions

We'll explore Spark SQL in this lab.

All the instructions can be found in the notebooks. Simply upload the notebook (for Scala or Python) into your Jupyter environment.

If you want to want to run the lab using Spark Shell, you can find the instruction for how to do that in the `spark-shell` directory.

## Run the notebooks

Make sure your Jupyter docker environment is running. Launch your browser on the Jupyter API and upload the notebooks for each lab into the work directory.

The notebooks can be found:

* Lab 01: SQL
    * Scala
        * [lesson-560-spark-sql/labs/lab-01-sql/notebooks/scala-560-lab-01-spark-sql.ipynb](lab-01-sql/notebooks/scala-560-lab-01-spark-sql.ipynb)
    * Python
        * [lesson-560-spark-sql/labs/lab-01-sql/notebooks/python-560-lab-01-spark-sql.ipynb](lab-01-sql/notebooks/python-560-lab-01-spark-sql.ipynb)
    * Spark Shell
        * [lesson-560-spark-sql/labs/lab-01-sql/spark-shell/instructions.md](lab-01-sql/spark-shell/instructions.md)

## Solutions

The solutions (which includes the Java code), can be found in the directory `lesson-560-spark-sql/solutions`.
